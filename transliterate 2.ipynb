{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Flatten, CuDNNLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Flatten, CuDNNLSTM\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from numpy import argmax\n",
    "import pandas as pd\n",
    "df = pd.read_excel('80.xlsx',  header=None)\n",
    "\n",
    "#df = df.sort_values(by = 2, ascending=False)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#df.loc[:,0] = first_col(df.loc[:,0])\n",
    "\n",
    "df.drop(labels=[119974], inplace=True)\n",
    "\n",
    "df[0]= df[0].apply(lambda x: '_'.join([i for i in x]))\n",
    "\n",
    "df[1] = df[1].apply(lambda x: x.replace(\" \",\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len0'] = [len(x) for x in df[0]]\n",
    "df['len1'] = [len(x) for x in df[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df[2] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2['len0'] == df2['len1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df2['len1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_alph = '_abcdefghijklmnopqrstuvwxyz'\n",
    "rus_alph = '_абвгдеёжзийклмнопрстуфхцчшщыьъэюя'\n",
    "\n",
    "eng_c2i = dict((c, i) for i, c in enumerate(eng_alph))\n",
    "eng_i2c = dict((i, c) for i, c in enumerate(eng_alph))\n",
    "\n",
    "rus_c2i = dict((c, i) for i, c in enumerate(rus_alph))\n",
    "rus_i2c = dict((i, c) for i, c in enumerate(rus_alph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char_rus = max([len(i) for i in df2[0]])\n",
    "\n",
    "max_char_eng = max([len(i) for i in df2[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_alph = max(len(eng_alph), len(rus_alph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(df2[df2.loc[:,1].str.contains('\\\\?')].index, inplace=True)\n",
    "\n",
    "df2.drop(df2[df2.loc[:,1].str.contains('ў')].index, inplace=True)\n",
    "\n",
    "df2.drop(df2[df2.loc[:,1].str.contains('’')].index, inplace=True)\n",
    "df2.drop(df2[df2.loc[:,0].str.contains('’')].index, inplace=True)\n",
    "\n",
    "df2.drop(df2[df2.loc[:,1].str.contains('і')].index, inplace=True)\n",
    "\n",
    "df2.drop(df2[df2.loc[:,1].str.contains('ј')].index, inplace=True)\n",
    "\n",
    "df2.drop(df2[df2.loc[:,1].str.contains('ќ')].index, inplace=True)\n",
    "\n",
    "df2.drop(df2[df2.loc[:,1].str.contains('ћ')].index, inplace=True)\n",
    "\n",
    "df2.drop(df2[df2.loc[:,0].str.contains('`')].index, inplace=True)\n",
    "\n",
    "df2[df2.loc[:,0].str.contains('`')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_enc = np.zeros((len(df2),max_char_rus,max_len_alph),dtype = 'uint8')\n",
    "#i - row\n",
    "#j - symbol position\n",
    "#k - character encoding\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    for j in range(max_char_rus):\n",
    "        for k in range(max_len_alph):\n",
    "            if len(df2.iloc[i,1])>j and k==rus_c2i[df2.iloc[i,1][j]]:\n",
    "                rus_enc[i,j,k] = 1\n",
    "            else:\n",
    "                rus_enc[i,j,k] = 0\n",
    "\n",
    "eng_enc = np.zeros((len(df2),max_char_eng,max_len_alph),dtype = 'uint8')\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    for j in range(max_char_eng):\n",
    "        for k in range(max_len_alph):\n",
    "            if len(df2.iloc[i,0])>j and k==eng_c2i[df2.iloc[i,0][j]]:\n",
    "                eng_enc[i,j,k] = 1\n",
    "            else:\n",
    "                eng_enc[i,j,k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('rus_enc.npy', rus_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('eng_enc.npy', eng_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70211, 39, 34)\n",
      "(70211, 39, 34)\n"
     ]
    }
   ],
   "source": [
    "print(eng_enc.shape)\n",
    "print(rus_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49147 samples, validate on 21064 samples\n",
      "Epoch 1/50\n",
      "49147/49147 [==============================] - 4s 74us/step - loss: 1.0202 - acc: 0.7546 - val_loss: 0.8399 - val_acc: 0.8297\n",
      "Epoch 2/50\n",
      "49147/49147 [==============================] - 2s 31us/step - loss: 0.7743 - acc: 0.8296 - val_loss: 0.7318 - val_acc: 0.8297\n",
      "Epoch 3/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.7063 - acc: 0.8296 - val_loss: 0.6792 - val_acc: 0.8297\n",
      "Epoch 4/50\n",
      "49147/49147 [==============================] - 2s 31us/step - loss: 0.6510 - acc: 0.8296 - val_loss: 0.6158 - val_acc: 0.8297\n",
      "Epoch 5/50\n",
      "49147/49147 [==============================] - 2s 31us/step - loss: 0.5675 - acc: 0.8301 - val_loss: 0.5137 - val_acc: 0.8436\n",
      "Epoch 6/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.4803 - acc: 0.8688 - val_loss: 0.4503 - val_acc: 0.8746\n",
      "Epoch 7/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.4252 - acc: 0.8813 - val_loss: 0.3994 - val_acc: 0.8935\n",
      "Epoch 8/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.3747 - acc: 0.9127 - val_loss: 0.3494 - val_acc: 0.9290\n",
      "Epoch 9/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.3252 - acc: 0.9400 - val_loss: 0.3010 - val_acc: 0.9471\n",
      "Epoch 10/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.2782 - acc: 0.9571 - val_loss: 0.2565 - val_acc: 0.9596\n",
      "Epoch 11/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.2365 - acc: 0.9634 - val_loss: 0.2183 - val_acc: 0.9673\n",
      "Epoch 12/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.2016 - acc: 0.9712 - val_loss: 0.1875 - val_acc: 0.9733\n",
      "Epoch 13/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.1742 - acc: 0.9743 - val_loss: 0.1638 - val_acc: 0.9745\n",
      "Epoch 14/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.1532 - acc: 0.9758 - val_loss: 0.1457 - val_acc: 0.9758\n",
      "Epoch 15/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.1373 - acc: 0.9780 - val_loss: 0.1323 - val_acc: 0.9795\n",
      "Epoch 16/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.1256 - acc: 0.9800 - val_loss: 0.1223 - val_acc: 0.9796\n",
      "Epoch 17/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.1168 - acc: 0.9806 - val_loss: 0.1149 - val_acc: 0.9807\n",
      "Epoch 18/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.1103 - acc: 0.9810 - val_loss: 0.1093 - val_acc: 0.9811\n",
      "Epoch 19/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.1054 - acc: 0.9809 - val_loss: 0.1051 - val_acc: 0.9790\n",
      "Epoch 20/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.1017 - acc: 0.9799 - val_loss: 0.1019 - val_acc: 0.9797\n",
      "Epoch 21/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.0988 - acc: 0.9793 - val_loss: 0.0994 - val_acc: 0.9782\n",
      "Epoch 22/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0965 - acc: 0.9777 - val_loss: 0.0974 - val_acc: 0.9775\n",
      "Epoch 23/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0947 - acc: 0.9745 - val_loss: 0.0957 - val_acc: 0.9775\n",
      "Epoch 24/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0932 - acc: 0.9726 - val_loss: 0.0944 - val_acc: 0.9705\n",
      "Epoch 25/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0920 - acc: 0.9695 - val_loss: 0.0932 - val_acc: 0.9659\n",
      "Epoch 26/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.0909 - acc: 0.9664 - val_loss: 0.0922 - val_acc: 0.9675\n",
      "Epoch 27/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0899 - acc: 0.9655 - val_loss: 0.0913 - val_acc: 0.9641\n",
      "Epoch 28/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.0891 - acc: 0.9633 - val_loss: 0.0906 - val_acc: 0.9612\n",
      "Epoch 29/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0884 - acc: 0.9616 - val_loss: 0.0899 - val_acc: 0.9597\n",
      "Epoch 30/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.0877 - acc: 0.9601 - val_loss: 0.0892 - val_acc: 0.9489\n",
      "Epoch 31/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.0871 - acc: 0.9508 - val_loss: 0.0887 - val_acc: 0.9532\n",
      "Epoch 32/50\n",
      "49147/49147 [==============================] - 2s 31us/step - loss: 0.0866 - acc: 0.9485 - val_loss: 0.0881 - val_acc: 0.9405\n",
      "Epoch 33/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.0861 - acc: 0.9446 - val_loss: 0.0877 - val_acc: 0.9410\n",
      "Epoch 34/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0856 - acc: 0.9407 - val_loss: 0.0872 - val_acc: 0.9418\n",
      "Epoch 35/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.0852 - acc: 0.9364 - val_loss: 0.0868 - val_acc: 0.9358\n",
      "Epoch 36/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0848 - acc: 0.9309 - val_loss: 0.0864 - val_acc: 0.9282\n",
      "Epoch 37/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0844 - acc: 0.9297 - val_loss: 0.0861 - val_acc: 0.9241\n",
      "Epoch 38/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0841 - acc: 0.9231 - val_loss: 0.0858 - val_acc: 0.9265\n",
      "Epoch 39/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0838 - acc: 0.9141 - val_loss: 0.0855 - val_acc: 0.9224\n",
      "Epoch 40/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0835 - acc: 0.9196 - val_loss: 0.0852 - val_acc: 0.9141\n",
      "Epoch 41/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0832 - acc: 0.9109 - val_loss: 0.0850 - val_acc: 0.9233\n",
      "Epoch 42/50\n",
      "49147/49147 [==============================] - 2s 31us/step - loss: 0.0830 - acc: 0.9096 - val_loss: 0.0847 - val_acc: 0.8681\n",
      "Epoch 43/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0828 - acc: 0.9025 - val_loss: 0.0845 - val_acc: 0.9137\n",
      "Epoch 44/50\n",
      "49147/49147 [==============================] - 2s 34us/step - loss: 0.0825 - acc: 0.9108 - val_loss: 0.0843 - val_acc: 0.9041\n",
      "Epoch 45/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0823 - acc: 0.9017 - val_loss: 0.0840 - val_acc: 0.8974\n",
      "Epoch 46/50\n",
      "49147/49147 [==============================] - 2s 33us/step - loss: 0.0821 - acc: 0.9084 - val_loss: 0.0838 - val_acc: 0.8997\n",
      "Epoch 47/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0819 - acc: 0.9019 - val_loss: 0.0836 - val_acc: 0.9102\n",
      "Epoch 48/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0817 - acc: 0.9052 - val_loss: 0.0835 - val_acc: 0.9108\n",
      "Epoch 49/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0815 - acc: 0.9083 - val_loss: 0.0833 - val_acc: 0.9021\n",
      "Epoch 50/50\n",
      "49147/49147 [==============================] - 2s 32us/step - loss: 0.0814 - acc: 0.9057 - val_loss: 0.0831 - val_acc: 0.9190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ddbbe4a550>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(CuDNNLSTM(34, input_shape = rus_enc.shape[1:],  return_sequences = True))\n",
    "#model.add(Dropout(0.1))\n",
    "#model.add(CuDNNLSTM(34,  return_sequences = True))\n",
    "\n",
    "\n",
    "#model.add(Dropout(0.1))\n",
    "#model.add(Dense(34, activation = 'sigmoid'))\n",
    "#model.add(CuDNNLSTM(34,  return_sequences = True))\n",
    "model.add(Dense(34, activation = 'softmax'))\n",
    "#model.add(LSTM(128))\n",
    "\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer= 'Adam', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(rus_enc, eng_enc, epochs=50, batch_size =1152,  validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('98acc30step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdfr_cols = [x for x in eng_alph]\n",
    "[bdfr_cols.append(\"?\") for i in range(7)]\n",
    "\n",
    "def mytranslate(word):\n",
    "    b = np.zeros((39,34))\n",
    "    for ix, char in enumerate(word):\n",
    "        b[ix, rus_c2i[char]] = 1\n",
    "    b = b.reshape((1, 39,34))\n",
    "    predicted = model.predict(b)\n",
    "    predicted = predicted.reshape(39,34)\n",
    "    dfr = pd.DataFrame(predicted, columns=bdfr_cols)\n",
    "    dfr.to_excel(word +'.xlsx')\n",
    "    dfr = round(dfr)\n",
    "    answer = []\n",
    "    for i, _ in dfr.iterrows():\n",
    "        try:\n",
    "            answer.append(dfr.loc[i,:][dfr.loc[i,:]==1].index[0])\n",
    "        except:\n",
    "            pass\n",
    "    return ''.join(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#DO NOT USE\n",
    "#############################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
